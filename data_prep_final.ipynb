{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b8ed67",
   "metadata": {},
   "source": [
    "# DATA CLEANING AND PREPARATION FOR MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8621ee",
   "metadata": {},
   "source": [
    "## MODULE IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f34642d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m vars_season\u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      4\u001b[0m     lst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mvars\u001b[39m[k]\n\u001b[1;32m      5\u001b[0m     lst \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_match\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_season\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_match\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m lst]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "vars_season= {}\n",
    "\n",
    "for k in vars.keys():\n",
    "    lst = vars[k]\n",
    "    lst = [x.replace('player_match','player_season') if 'player_match' in x else x for x in lst]\n",
    "    lst = [f\"{x}_90\" if 'player_season' in x else x for x in lst]\n",
    "    vars_season[k] = lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93523ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "from stored_vars import vars\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def split_name(name: str):\n",
    "    '''\n",
    "    Function takes a string as an argument and splits it based on the amount of words in the string. \n",
    "    First word is the first name, other words form the last name.\n",
    "    '''\n",
    "    if len(name.split(' ')) == 2:\n",
    "        first_name = name.split(' ')[0]\n",
    "        last_name = name.split(' ')[1]\n",
    "    else:\n",
    "        first_name = name.split(' ')[0]\n",
    "        last_name = ' '.join(name.split(' ')[1:])\n",
    "    \n",
    "    return first_name, last_name\n",
    "\n",
    "\n",
    "def clean_name(name):\n",
    "    \"\"\"Clean and normalize names for better matching\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    # Convert to lowercase, remove accents, extra spaces\n",
    "    name = str(name).lower().strip()\n",
    "    name = re.sub(r'[^\\w\\s-]', '', name)  # Remove special chars except hyphens\n",
    "    name = re.sub(r'\\s+', ' ', name)  # Normalize spaces\n",
    "    return name\n",
    "\n",
    "def similarity_score(name1, name2):\n",
    "    \"\"\"Calculate similarity between two names\"\"\"\n",
    "    return SequenceMatcher(None, clean_name(name1), clean_name(name2)).ratio()\n",
    "\n",
    "\n",
    "def map_players_by_name_and_team(tf_df, game_df, name_threshold=0.7, team_boost=0.15):\n",
    "    \"\"\"\n",
    "    Map players using both player_name and team_name for improved accuracy.\n",
    "    \n",
    "    Args:\n",
    "        tf_df (DataFrame): Transfer data with 'player_id', 'player_name', 'team_name'\n",
    "        game_df (DataFrame): Game data with 'player_id', 'player_name', 'team_name' \n",
    "        name_threshold (float): Minimum player name similarity\n",
    "        team_boost (float): Score boost when team names match well\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Mapping with player IDs, names, teams, and match scores\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get unique players from both datasets\n",
    "    tf_unique = tf_df[['player_id', 'player_name', 'team_name']].drop_duplicates()\n",
    "    game_unique = game_df[['player_id', 'player_name', 'team_name']].drop_duplicates()\n",
    "    \n",
    "    mappings = []\n",
    "    \n",
    "    for _, game_player in game_unique.iterrows():\n",
    "        game_name = game_player['player_name']\n",
    "        game_id = game_player['player_id']\n",
    "        game_team = game_player['team_name']\n",
    "        \n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        \n",
    "        for _, tf_player in tf_unique.iterrows():\n",
    "            tf_name = tf_player['player_name']\n",
    "            tf_id = tf_player['player_id']\n",
    "            tf_team = tf_player['team_name']\n",
    "            \n",
    "            # Calculate name similarity\n",
    "            name_score = similarity_score(game_name, tf_name)\n",
    "            \n",
    "            # Skip if name similarity is too low\n",
    "            if name_score < name_threshold:\n",
    "                continue\n",
    "                \n",
    "            # Calculate team similarity\n",
    "            team_score = similarity_score(game_team, tf_team)\n",
    "            \n",
    "            # Combined score: boost name score if teams match well\n",
    "            final_score = name_score\n",
    "            if team_score > 0.8:  # Strong team match\n",
    "                final_score += team_boost\n",
    "            \n",
    "            if final_score > best_score:\n",
    "                best_score = final_score\n",
    "                best_match = {\n",
    "                    'tf_player_id': tf_id,\n",
    "                    'game_player_id': game_id,\n",
    "                    'tf_player_name': tf_name,\n",
    "                    'game_player_name': game_name,\n",
    "                    'tf_team_name': tf_team,\n",
    "                    'game_team_name': game_team,\n",
    "                    'name_similarity': name_score,\n",
    "                    'team_similarity': team_score,\n",
    "                    'final_score': final_score,\n",
    "                    'team_match': team_score > 0.8\n",
    "                }\n",
    "        \n",
    "        if best_match:\n",
    "            mappings.append(best_match)\n",
    "    \n",
    "    return pd.DataFrame(mappings)\n",
    "\n",
    "\n",
    "def map_players_by_name(tf_players_df, game_data_df, similarity_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Map players between transfer data and game data based on player names only.\n",
    "    \n",
    "    Args:\n",
    "        tf_players_df (DataFrame): Transfer players with 'player_id' and 'player_name'\n",
    "        game_data_df (DataFrame): Game data with 'player_id' and 'player_name'\n",
    "        similarity_threshold (float): Minimum similarity score for matching\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Mapping with tf_player_id, game_player_id, names, and similarity_score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get unique players from both datasets\n",
    "    tf_unique = tf_players_df[['player_id', 'player_name']].drop_duplicates()\n",
    "    game_unique = game_data_df[['player_id', 'player_name']].drop_duplicates()\n",
    "    \n",
    "    mappings = []\n",
    "    \n",
    "    for _, game_player in game_unique.iterrows():\n",
    "        game_name = game_player['player_name']\n",
    "        game_id = game_player['player_id']\n",
    "        \n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        \n",
    "        for _, tf_player in tf_unique.iterrows():\n",
    "            tf_name = tf_player['player_name']\n",
    "            tf_id = tf_player['player_id']\n",
    "            \n",
    "            score = similarity_score(game_name, tf_name)\n",
    "            \n",
    "            if score > best_score and score >= similarity_threshold:\n",
    "                best_score = score\n",
    "                best_match = {\n",
    "                    'tf_player_id': tf_id,\n",
    "                    'game_player_id': game_id,\n",
    "                    'tf_player_name': tf_name,\n",
    "                    'game_player_name': game_name,\n",
    "                    'similarity_score': score\n",
    "                }\n",
    "        \n",
    "        if best_match:\n",
    "            mappings.append(best_match)\n",
    "    \n",
    "    return pd.DataFrame(mappings)\n",
    "\n",
    "\n",
    "\n",
    "def compute_transfer_values(\n",
    "    df: pd.DataFrame,\n",
    "    player_col: str = \"player_name\",\n",
    "    value_col: str = \"value\",\n",
    "    date_col: str = \"marketValue.determined\",\n",
    "    freqs=(\"half_year\", \"quarter\"),\n",
    "    drop_na_dates: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute transfer values per player and time interval\n",
    "    (half-year Jan–Jun/Jul–Dec and/or quarter).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input data containing player, value, and date columns.\n",
    "    player_col : str, default \"player_name\"\n",
    "        Column name identifying the player.\n",
    "    value_col : str, default \"value\"\n",
    "        Column with transfer value (numeric).\n",
    "    date_col : str, default \"marketValue.determined\"\n",
    "        Column with the date of determination (datetime-like).\n",
    "    freqs : tuple of {\"half_year\", \"quarter\"}\n",
    "        Which period granularities to include.\n",
    "    drop_na_dates : bool, default True\n",
    "        Drop rows where the date cannot be parsed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Columns: [player_col, \"year\", \"period_type\", \"period\", value_col]\n",
    "    \"\"\"\n",
    "\n",
    "    # --- validation ---\n",
    "    for col in [player_col, value_col, date_col]:\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"Column '{col}' not found. Available: {list(df.columns)}\")\n",
    "\n",
    "    work = df.copy()\n",
    "    work[date_col] = pd.to_datetime(work[date_col], errors=\"coerce\")\n",
    "    if drop_na_dates:\n",
    "        work = work.dropna(subset=[date_col])\n",
    "\n",
    "    work[value_col] = pd.to_numeric(work[value_col], errors=\"coerce\").fillna(0)\n",
    "\n",
    "    work[\"year\"] = work[date_col].dt.year\n",
    "    work[\"_month\"] = work[date_col].dt.month\n",
    "    work[\"half_year\"] = work[\"_month\"].map(lambda m: \"H1\" if m <= 6 else \"H2\")\n",
    "    work[\"quarter\"] = work[date_col].dt.quarter.map(lambda q: f\"Q{q}\")\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    if \"half_year\" in freqs:\n",
    "        g = (work\n",
    "             .groupby([player_col, \"year\", \"half_year\"])[value_col]\n",
    "             .mean()\n",
    "             .reset_index())\n",
    "        g = g.rename(columns={\"half_year\": \"period\"})\n",
    "        g[\"period_type\"] = \"half_year\"\n",
    "        outputs.append(g[[player_col, \"year\", \"period_type\", \"period\", value_col]])\n",
    "\n",
    "    if \"quarter\" in freqs:\n",
    "        g = (work\n",
    "             .groupby([player_col, \"year\", \"quarter\"])[value_col]\n",
    "             .mean()\n",
    "             .reset_index())\n",
    "        g = g.rename(columns={\"quarter\": \"period\"})\n",
    "        g[\"period_type\"] = \"quarter\"\n",
    "        outputs.append(g[[player_col, \"year\", \"period_type\", \"period\", value_col]])\n",
    "\n",
    "    if not outputs:\n",
    "        raise ValueError(\"No valid frequencies selected. Use 'half_year' and/or 'quarter'.\")\n",
    "\n",
    "    out = pd.concat(outputs, ignore_index=True)\n",
    "\n",
    "    # Sort nicely\n",
    "    order_map = {\"H1\": 1, \"H2\": 2, \"Q1\": 1, \"Q2\": 2, \"Q3\": 3, \"Q4\": 4}\n",
    "    out[\"_sort\"] = out[\"period\"].map(order_map).fillna(9)\n",
    "    out = out.sort_values([player_col, \"year\", \"period_type\", \"_sort\"]).drop(columns=\"_sort\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def compute_transfer_values(\n",
    "    df: pd.DataFrame,\n",
    "    player_col: str = \"player_name\",\n",
    "    value_col: str = \"value\",\n",
    "    date_col: str = \"marketValue.determined\",\n",
    "    freqs=(\"half_year\", \"quarter\"),\n",
    "    drop_na_dates: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute transfer values per player and time interval\n",
    "    (half-year Jan–Jun/Jul–Dec and/or quarter), including mean age.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input data containing player, value, age, and date columns.\n",
    "    player_col : str, default \"player_name\"\n",
    "        Column name identifying the player.\n",
    "    value_col : str, default \"value\"\n",
    "        Column with transfer value (numeric).\n",
    "    date_col : str, default \"marketValue.determined\"\n",
    "        Column with the date of determination (datetime-like).\n",
    "    freqs : tuple of {\"half_year\", \"quarter\"}\n",
    "        Which period granularities to include.\n",
    "    drop_na_dates : bool, default True\n",
    "        Drop rows where the date cannot be parsed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Columns: [player_col, \"year\", \"period_type\", \"period\", value_col, \"age\"]\n",
    "    \"\"\"\n",
    "\n",
    "    # --- validation ---\n",
    "    for col in [player_col, value_col, date_col, \"age\"]:\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"Column '{col}' not found. Available: {list(df.columns)}\")\n",
    "\n",
    "    work = df.copy()\n",
    "    work[date_col] = pd.to_datetime(work[date_col], errors=\"coerce\")\n",
    "    if drop_na_dates:\n",
    "        work = work.dropna(subset=[date_col])\n",
    "\n",
    "    work[value_col] = pd.to_numeric(work[value_col], errors=\"coerce\").fillna(0)\n",
    "    work[\"age\"] = pd.to_numeric(work[\"age\"], errors=\"coerce\")\n",
    "\n",
    "    work[\"year\"] = work[date_col].dt.year\n",
    "    work[\"_month\"] = work[date_col].dt.month\n",
    "    work[\"half_year\"] = work[\"_month\"].map(lambda m: \"H1\" if m <= 6 else \"H2\")\n",
    "    work[\"quarter\"] = work[date_col].dt.quarter.map(lambda q: f\"Q{q}\")\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    if \"half_year\" in freqs:\n",
    "        g = (\n",
    "            work\n",
    "            .groupby([player_col, \"year\", \"half_year\"], as_index=False)\n",
    "            .agg({value_col: \"mean\", \"age\": \"mean\"})\n",
    "            .rename(columns={\"half_year\": \"period\"})\n",
    "        )\n",
    "        g[\"period_type\"] = \"half_year\"\n",
    "        outputs.append(g[[player_col, \"year\", \"period_type\", \"period\", value_col, \"age\"]])\n",
    "\n",
    "    if \"quarter\" in freqs:\n",
    "        g = (\n",
    "            work\n",
    "            .groupby([player_col, \"year\", \"quarter\"], as_index=False)\n",
    "            .agg({value_col: \"mean\", \"age\": \"mean\"})\n",
    "            .rename(columns={\"quarter\": \"period\"})\n",
    "        )\n",
    "        g[\"period_type\"] = \"quarter\"\n",
    "        outputs.append(g[[player_col, \"year\", \"period_type\", \"period\", value_col, \"age\"]])\n",
    "\n",
    "    if not outputs:\n",
    "        raise ValueError(\"No valid frequencies selected. Use 'half_year' and/or 'quarter'.\")\n",
    "\n",
    "    out = pd.concat(outputs, ignore_index=True)\n",
    "\n",
    "    # Sort nicely\n",
    "    order_map = {\"H1\": 1, \"H2\": 2, \"Q1\": 1, \"Q2\": 2, \"Q3\": 3, \"Q4\": 4}\n",
    "    out[\"_sort\"] = out[\"period\"].map(order_map).fillna(9)\n",
    "    out = out.sort_values([player_col, \"year\", \"period_type\", \"_sort\"]).drop(columns=\"_sort\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def add_period_columns(\n",
    "    df: pd.DataFrame,\n",
    "    date_col: str,\n",
    "    out_year: str = \"year\",\n",
    "    out_quarter: str = \"quarter\",\n",
    "    out_half: str = \"half_year\",\n",
    "    drop_na_dates: bool = False,\n",
    "    inplace: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add year, quarter (Q1..Q4), and half-year (H1/H2) columns to a DataFrame that has a date column.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe.\n",
    "    date_col : str\n",
    "        Name of the date column in df (datetime-like or string parseable to datetime).\n",
    "    out_year : str, default \"year\"\n",
    "        Output column name for year.\n",
    "    out_quarter : str, default \"quarter\"\n",
    "        Output column name for quarter label (\"Q1\"..\"Q4\").\n",
    "    out_half : str, default \"half_year\"\n",
    "        Output column name for half-year label (\"H1\"/\"H2\").\n",
    "    drop_na_dates : bool, default False\n",
    "        If True, drop rows where date parsing failed; otherwise, keep rows with NaT.\n",
    "    inplace : bool, default False\n",
    "        If True, modify df in place and return it. If False, work on a copy.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with added period columns.\n",
    "    \"\"\"\n",
    "    work = df if inplace else df.copy()\n",
    "    if date_col not in work.columns:\n",
    "        raise KeyError(f\"Date column '{date_col}' not found. Available: {list(work.columns)}\")\n",
    "    \n",
    "    work[date_col] = pd.to_datetime(work[date_col], errors=\"coerce\")\n",
    "    if drop_na_dates:\n",
    "        work = work.dropna(subset=[date_col])\n",
    "    \n",
    "    work[out_year] = work[date_col].dt.year\n",
    "    work[out_quarter] = work[date_col].dt.quarter.map(lambda q: f\"Q{q}\" if pd.notna(q) else None)\n",
    "    work[\"_month__tmp\"] = work[date_col].dt.month\n",
    "    work[out_half] = work[\"_month__tmp\"].map(lambda m: \"H1\" if pd.notna(m) and m <= 6 else (\"H2\" if pd.notna(m) else None))\n",
    "    work = work.drop(columns=[\"_month__tmp\"])\n",
    "    \n",
    "    return work\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9706f424",
   "metadata": {},
   "source": [
    "## DATA LOAD & PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d0457d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n",
      "16\n",
      "143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/2352698896.py:2: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  seasonStats = pd.read_csv('datasets/gamedata/SeasonStats.csv',sep=';')\n"
     ]
    }
   ],
   "source": [
    "## load season stats and keep relevant competitions:\n",
    "seasonStats = pd.read_csv('datasets/gamedata/SeasonStats.csv',sep=';')\n",
    "\n",
    "keep_comps = ['Bundesliga','Eliteserien','Eredivisie','Jupiler Pro League','Super League','Primeira Liga']\n",
    "seasonStats = seasonStats[seasonStats['competition_name'].isin(keep_comps)]\n",
    "\n",
    "### Filter on minutes played for the season and calculate number of 90s played:\n",
    "seasonStats = seasonStats[seasonStats['player_season_minutes'] >= 600]\n",
    "seasonStats['#_90s'] = (seasonStats['player_season_minutes'] / 90).round(0).astype(int)\n",
    "\n",
    "## Clean up the positions\n",
    "seasonStats['primary_position_group'] = (\n",
    "    seasonStats['primary_position']\n",
    "    .str.replace('Right','')\n",
    "    .str.replace('Left','')\n",
    "    .str.replace('Centre Defensive','Defensive')\n",
    "    .str.replace('Centre Attacking','Attacking')\n",
    "    .str.replace('Centre Midfielder','Midfielder')\n",
    "    .str.lstrip(' ')\n",
    "    .str.rstrip(' ')\n",
    ")\n",
    "\n",
    "seasonStats['secondary_position_group'] = (\n",
    "    seasonStats['secondary_position']\n",
    "    .str.replace('Right','')\n",
    "    .str.replace('Left','')\n",
    "    .str.replace('Centre Defensive','Defensive')\n",
    "    .str.replace('Centre Attacking','Attacking')\n",
    "    .str.replace('Centre Midfielder','Midfielder')\n",
    "    .str.lstrip(' ')\n",
    "    .str.rstrip(' ')\n",
    ")\n",
    "seasonStats = seasonStats.dropna(how='all',axis=1)\n",
    "seasonStats = seasonStats.dropna(subset='primary_position')\n",
    "seasonStats = seasonStats[seasonStats.primary_position != 'Goalkeeper']\n",
    "seasonStats = seasonStats.drop(\n",
    "    columns=[\n",
    "        'player_season_obv_gk_90','player_season_ot_shots_faced_ratio',\n",
    "        'player_season_penalty_conversion_ratio','player_known_name',\n",
    "        'player_first_name','player_last_name','player_weight','secondary_position_group',\n",
    "        'player_season_gsaa_ratio','secondary_position','player_height','primary_position',\n",
    "        'account_id','team_id','player_season_gsaa_90','player_season_360_minutes','player_season_most_recent_match'\n",
    "        ]\n",
    ")\n",
    "\n",
    "vars_with_na = seasonStats.isna().sum().sort_values(ascending=False).index.tolist()\n",
    "print(len(vars_with_na))\n",
    "id_vars = ['player_season_minutes','player_id','country_id','birth_date',\n",
    " 'player_female',\n",
    " 'season_name',\n",
    " 'season_id',\n",
    " 'competition_name',\n",
    " 'competition_id','player_season_clcaa',\n",
    " 'team_name', 'player_name', 'primary_position_group',\n",
    " 'team_name', 'player_name', 'primary_position_group']\n",
    "print(len(id_vars))\n",
    "\n",
    "vars_with_na = [x for x in vars_with_na if x not in id_vars]\n",
    "print(len(vars_with_na))\n",
    "\n",
    "\n",
    "for var in vars_with_na:\n",
    "    seasonStats[var] = seasonStats[var].fillna(seasonStats[var].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe54b66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BE1',\n",
       " 'competition_id',\n",
       " 'SE1',\n",
       " 'A1',\n",
       " 'DK1',\n",
       " 'JAP1',\n",
       " 'NL1',\n",
       " 'NO1',\n",
       " 'PO1',\n",
       " 'C1',\n",
       " 'MLS1']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfTeams['competition_id'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d574cfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12978\n",
      "123243\n",
      "136221\n",
      "114171\n"
     ]
    }
   ],
   "source": [
    "## load tf team data\n",
    "tfTeams = pd.read_csv('datasets/transfermarkt_teams.csv',sep=',')\n",
    "tfTeams['team_name'] = tfTeams['team_url'].str.split('/').str[3].str.replace('-',' ')\n",
    "tfTeams['team_id'] = tfTeams['team_url'].str.split('/').str[-3]\n",
    "\n",
    "keep_comps_ids = ['A1','DK1','NL1','BE1','C1','PO1']\n",
    "tfTeams = tfTeams[tfTeams['competition_id'].isin(keep_comps_ids)]\n",
    "\n",
    "## load tf player links\n",
    "links = pd.read_csv('datasets/transfermarkt_player_links.csv',sep=',')\n",
    "links['player_name'] = links['player_url'].str.split('/').str[1].str.replace('-',' ')\n",
    "\n",
    "## loaf tf MV data\n",
    "tfValues1 = pd.read_csv('datasets/transfermarkt_players_values.csv',sep=',')\n",
    "print(len(tfValues1))\n",
    "tfValues2 = pd.read_csv('datasets/transfermarkt_players_values_2.csv',sep=',')\n",
    "print(len(tfValues2))\n",
    "\n",
    "tfValues = pd.concat([tfValues1,tfValues2],ignore_index=True)\n",
    "print(len(tfValues))\n",
    "\n",
    "tfValues = tfValues.drop_duplicates(subset=['playerId','marketValue.determined'])\n",
    "print(len(tfValues))\n",
    "\n",
    "tfValues['clubId'] = tfValues['clubId'].astype(str)\n",
    "tfValues = tfValues[~tfValues['marketValue.compact.suffix'].isna()]\n",
    "tfValues = tfValues.merge(links[['player_id','player_name']],\n",
    "                          left_on='playerId',\n",
    "                          right_on='player_id',\n",
    "                          how='left')\n",
    "tfValues = tfValues.merge(tfTeams[['team_id','team_name']],left_on = 'clubId',\n",
    "                          right_on='team_id',how='left')\n",
    "\n",
    "tfValues = tfValues[tfValues['marketValue.compact.content'] != 'marketValue.compact.content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30afa70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = pd.read_csv('datasets/transfermarkt_seasons_2.csv',sep=',')\n",
    "seasons = seasons.competition_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2b32ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3779671005.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tfValues['marketValue.compact.content'] = tfValues['marketValue.compact.content'].str.replace(',','.')\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3779671005.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tfValues['marketValue.compact.content'] = tfValues['marketValue.compact.content'].astype(float)\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3779671005.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tfValues['value'] = valueList\n"
     ]
    }
   ],
   "source": [
    "## keep needed cols and set values to float\n",
    "tfValues = tfValues[['player_name','player_id','age','team_name','marketValue.value','marketValue.compact.content',\n",
    "                     'marketValue.compact.suffix','marketValue.determined']]\n",
    "\n",
    "tfValues['marketValue.compact.content'] = tfValues['marketValue.compact.content'].str.replace(',','.')\n",
    "tfValues['marketValue.compact.content'] = tfValues['marketValue.compact.content'].astype(float)\n",
    "\n",
    "## use suffix col to create a correct value in format \"x.y\" in millions.\n",
    "valueList = []\n",
    "for i in range(len(tfValues)):\n",
    "    val = tfValues['marketValue.compact.content'].iloc[i]\n",
    "    suff = tfValues['marketValue.compact.suffix'].iloc[i]\n",
    "\n",
    "    if suff == 'K':\n",
    "        valueList.append(val/1000)\n",
    "    elif suff == 'M':\n",
    "        valueList.append(val)\n",
    "\n",
    "tfValues['value'] = valueList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3143b234",
   "metadata": {},
   "source": [
    "## Mapping datasources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f959041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use mapping function to find player names that match. After some visual inspection 0.9 seems like a good threshold.\n",
    "mapped_players = map_players_by_name_and_team(seasonStats, tfValues, name_threshold=0.7, team_boost=0.15)\n",
    "mapped_players_solid = mapped_players[mapped_players.final_score >= 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dbeecc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tf_player_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "game_player_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tf_player_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "game_player_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tf_team_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "game_team_name",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "name_similarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "team_similarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "final_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "team_match",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "2aa47395-f136-4fca-b742-57d758b2099e",
       "rows": [
        [
         "0",
         "34930",
         "428920.0",
         "Kevin Mac Allister",
         "kevin mac allister",
         "Union Saint-Gilloise",
         null,
         "1.0",
         "0.0",
         "1.0",
         "False"
        ],
        [
         "1",
         "34930",
         "428920.0",
         "Kevin Mac Allister",
         "kevin mac allister",
         "Union Saint-Gilloise",
         "royale union saint gilloise",
         "1.0",
         "0.8085106382978723",
         "1.15",
         "True"
        ],
        [
         "2",
         "52221",
         "660746.0",
         "Fedde Leysen",
         "fedde leysen",
         "PSV Eindhoven II",
         null,
         "1.0",
         "0.0",
         "1.0",
         "False"
        ],
        [
         "3",
         "52221",
         "660746.0",
         "Fedde Leysen",
         "fedde leysen",
         "Union Saint-Gilloise",
         "royale union saint gilloise",
         "1.0",
         "0.8085106382978723",
         "1.15",
         "True"
        ],
        [
         "4",
         "3880",
         "244221.0",
         "Christian Burgess",
         "christian burgess",
         "Union Saint-Gilloise",
         null,
         "1.0",
         "0.0",
         "1.0",
         "False"
        ],
        [
         "5",
         "3880",
         "244221.0",
         "Christian Burgess",
         "christian burgess",
         "Union Saint-Gilloise",
         "royale union saint gilloise",
         "1.0",
         "0.8085106382978723",
         "1.15",
         "True"
        ],
        [
         "6",
         "9432",
         "450958.0",
         "Ross Sykes",
         "ross sykes",
         "Union Saint-Gilloise",
         "royale union saint gilloise",
         "1.0",
         "0.8085106382978723",
         "1.15",
         "True"
        ],
        [
         "7",
         "431945",
         "1250976.0",
         "Mamadou Thierno Barry",
         "mamadou thierno barry",
         "Tromsø",
         "tromso il",
         "1.0",
         "0.6666666666666666",
         "1.0",
         "False"
        ],
        [
         "8",
         "431945",
         "1250976.0",
         "Mamadou Thierno Barry",
         "mamadou thierno barry",
         "Tromsø",
         "royale union saint gilloise",
         "1.0",
         "0.18181818181818182",
         "1.0",
         "False"
        ],
        [
         "9",
         "131245",
         "72736.0",
         "Guillaume François",
         "guillaume francois",
         "Union Saint-Gilloise",
         null,
         "0.9444444444444444",
         "0.0",
         "0.9444444444444444",
         "False"
        ],
        [
         "10",
         "131245",
         "72736.0",
         "Guillaume François",
         "guillaume francois",
         "Union Saint-Gilloise",
         "rsc charleroi",
         "0.9444444444444444",
         "0.30303030303030304",
         "0.9444444444444444",
         "False"
        ],
        [
         "11",
         "131245",
         "72736.0",
         "Guillaume François",
         "guillaume francois",
         "Union Saint-Gilloise",
         "beerschot v a ",
         "0.9444444444444444",
         "0.06060606060606061",
         "0.9444444444444444",
         "False"
        ],
        [
         "12",
         "131245",
         "72736.0",
         "Guillaume François",
         "guillaume francois",
         "Union Saint-Gilloise",
         "royale union saint gilloise",
         "0.9444444444444444",
         "0.8085106382978723",
         "1.0944444444444443",
         "True"
        ],
        [
         "13",
         "43702",
         "569845.0",
         "Charles Vanhoutte",
         "charles vanhoutte",
         "Cercle Brugge",
         "cercle brugge",
         "1.0",
         "1.0",
         "1.15",
         "True"
        ],
        [
         "14",
         "43702",
         "569845.0",
         "Charles Vanhoutte",
         "charles vanhoutte",
         "Union Saint-Gilloise",
         "royale union saint gilloise",
         "1.0",
         "0.8085106382978723",
         "1.15",
         "True"
        ],
        [
         "15",
         "132439",
         "592403.0",
         "Adem Zorgane",
         "adem zorgane",
         "Sporting Charleroi",
         null,
         "1.0",
         "0.0",
         "1.0",
         "False"
        ],
        [
         "16",
         "132439",
         "592403.0",
         "Adem Zorgane",
         "adem zorgane",
         "Sporting Charleroi",
         "rsc charleroi",
         "1.0",
         "0.7096774193548387",
         "1.0",
         "False"
        ],
        [
         "17",
         "156735",
         "655021.0",
         "Kamiel Van de Perre",
         "kamiel van de perre",
         "Jong Genk",
         null,
         "1.0",
         "0.0",
         "1.0",
         "False"
        ],
        [
         "18",
         "156735",
         "655021.0",
         "Kamiel Van de Perre",
         "kamiel van de perre",
         "Union Saint-Gilloise",
         "royale union saint gilloise",
         "1.0",
         "0.8085106382978723",
         "1.15",
         "True"
        ],
        [
         "19",
         "17031",
         "268327.0",
         "Mathias Rasmussen",
         "mathias rasmussen",
         "Brann",
         null,
         "1.0",
         "0.0",
         "1.0",
         "False"
        ],
        [
         "20",
         "17031",
         "268327.0",
         "Mathias Rasmussen",
         "mathias rasmussen",
         "Brann",
         "fc nordsjaelland",
         "1.0",
         "0.2857142857142857",
         "1.0",
         "False"
        ],
        [
         "21",
         "17031",
         "268327.0",
         "Mathias Rasmussen",
         "mathias rasmussen",
         "Brann",
         "sk brann",
         "1.0",
         "0.7692307692307693",
         "1.0",
         "False"
        ],
        [
         "22",
         "17031",
         "268327.0",
         "Mathias Rasmussen",
         "mathias rasmussen",
         "Union Saint-Gilloise",
         "royale union saint gilloise",
         "1.0",
         "0.8085106382978723",
         "1.15",
         "True"
        ],
        [
         "23",
         "143974",
         "945021.0",
         "Anan Khalaili",
         "anan khalaili",
         "Union Saint-Gilloise",
         null,
         "1.0",
         "0.0",
         "1.0",
         "False"
        ],
        [
         "24",
         "143974",
         "945021.0",
         "Anan Khalaili",
         "anan khalaili",
         "Union Saint-Gilloise",
         "royale union saint gilloise",
         "1.0",
         "0.8085106382978723",
         "1.15",
         "True"
        ],
        [
         "25",
         "23918",
         "340166.0",
         "Alessio Castro-Montes",
         "alessio castro montes",
         "Union Saint-Gilloise",
         null,
         "0.9523809523809523",
         "0.0",
         "0.9523809523809523",
         "False"
        ],
        [
         "26",
         "23918",
         "340166.0",
         "Alessio Castro-Montes",
         "alessio castro montes",
         "Union Saint-Gilloise",
         "kas eupen",
         "0.9523809523809523",
         "0.20689655172413793",
         "0.9523809523809523",
         "False"
        ],
        [
         "27",
         "23918",
         "340166.0",
         "Alessio Castro-Montes",
         "alessio castro montes",
         "Union Saint-Gilloise",
         "kaa gent",
         "0.9523809523809523",
         "0.21428571428571427",
         "0.9523809523809523",
         "False"
        ],
        [
         "28",
         "23918",
         "340166.0",
         "Alessio Castro-Montes",
         "alessio castro montes",
         "Union Saint-Gilloise",
         "royale union saint gilloise",
         "0.9523809523809523",
         "0.8085106382978723",
         "1.1023809523809522",
         "True"
        ],
        [
         "29",
         "443610",
         "509463.0",
         "Ousseynou Niang",
         "ousseynou niang",
         "Union Saint-Gilloise",
         null,
         "1.0",
         "0.0",
         "1.0",
         "False"
        ],
        [
         "30",
         "443610",
         "509463.0",
         "Ousseynou Niang",
         "ousseynou niang",
         "Union Saint-Gilloise",
         "royale union saint gilloise",
         "1.0",
         "0.8085106382978723",
         "1.15",
         "True"
        ],
        [
         "31",
         "28586",
         "486039.0",
         "Anouar Ait El Hadj",
         "anouar ait el hadj",
         "RSC Anderlecht",
         "rsc anderlecht",
         "1.0",
         "1.0",
         "1.15",
         "True"
        ],
        [
         "32",
         "28586",
         "486039.0",
         "Anouar Ait El Hadj",
         "anouar ait el hadj",
         "KRC Genk",
         "krc genk",
         "1.0",
         "1.0",
         "1.15",
         "True"
        ],
        [
         "33",
         "28586",
         "486039.0",
         "Anouar Ait El Hadj",
         "anouar ait el hadj",
         "Union Saint-Gilloise",
         "royale union saint gilloise",
         "1.0",
         "0.8085106382978723",
         "1.15",
         "True"
        ],
        [
         "34",
         "3625",
         "232271.0",
         "Sofiane Boufal",
         "sofiane boufal",
         "Union Saint-Gilloise",
         null,
         "1.0",
         "0.0",
         "1.0",
         "False"
        ],
        [
         "35",
         "3625",
         "232271.0",
         "Sofiane Boufal",
         "sofiane boufal",
         "Union Saint-Gilloise",
         "royale union saint gilloise",
         "1.0",
         "0.8085106382978723",
         "1.15",
         "True"
        ],
        [
         "36",
         "147710",
         "492634.0",
         "Henok Teklab",
         "henok teklab",
         "Union Saint-Gilloise",
         null,
         "1.0",
         "0.0",
         "1.0",
         "False"
        ],
        [
         "37",
         "147710",
         "492634.0",
         "Henok Teklab",
         "henok teklab",
         "Union Saint-Gilloise",
         "royale union saint gilloise",
         "1.0",
         "0.8085106382978723",
         "1.15",
         "True"
        ],
        [
         "38",
         "438432",
         "888785.0",
         "Promise David",
         "promise david",
         "Union Saint-Gilloise",
         null,
         "1.0",
         "0.0",
         "1.0",
         "False"
        ],
        [
         "39",
         "438432",
         "888785.0",
         "Promise David",
         "promise david",
         "Union Saint-Gilloise",
         "royale union saint gilloise",
         "1.0",
         "0.8085106382978723",
         "1.15",
         "True"
        ],
        [
         "41",
         "306782",
         "979410.0",
         "Mohammed Gadafi Fuseini",
         "mohammed fuseini",
         "Randers FC",
         "randers fc",
         "0.8205128205128205",
         "1.0",
         "0.9705128205128205",
         "True"
        ],
        [
         "42",
         "306782",
         "979410.0",
         "Mohammed Gadafi Fuseini",
         "mohammed fuseini",
         "Union Saint-Gilloise",
         "royale union saint gilloise",
         "0.8205128205128205",
         "0.8085106382978723",
         "0.9705128205128205",
         "True"
        ],
        [
         "53",
         "89251",
         "738774.0",
         "Zeno Van Den Bosch",
         "zeno van den bosch",
         "Antwerp",
         "royal antwerpen fc",
         "1.0",
         "0.56",
         "1.0",
         "False"
        ],
        [
         "54",
         "386897",
         "1030663.0",
         "Yuto Tsunashima",
         "yuto tsunashima",
         "Tokyo Verdy",
         "tokyo verdy",
         "1.0",
         "1.0",
         "1.15",
         "True"
        ],
        [
         "55",
         "15783",
         "193469.0",
         "Björn Engels",
         "bjorn engels",
         "Antwerp",
         null,
         "0.9166666666666666",
         "0.0",
         "0.9166666666666666",
         "False"
        ],
        [
         "56",
         "15783",
         "193469.0",
         "Björn Engels",
         "bjorn engels",
         "Antwerp",
         "fc brugge",
         "0.9166666666666666",
         "0.125",
         "0.9166666666666666",
         "False"
        ],
        [
         "57",
         "15783",
         "193469.0",
         "Björn Engels",
         "bjorn engels",
         "Antwerp",
         "royal antwerpen fc",
         "0.9166666666666666",
         "0.56",
         "0.9166666666666666",
         "False"
        ],
        [
         "58",
         "23685",
         "338637.0",
         "Daam Foulon",
         "daam foulon",
         "Mechelen",
         null,
         "1.0",
         "0.0",
         "1.0",
         "False"
        ],
        [
         "59",
         "23685",
         "338637.0",
         "Daam Foulon",
         "daam foulon",
         "Mechelen",
         "kv mechelen",
         "1.0",
         "0.8421052631578947",
         "1.15",
         "True"
        ],
        [
         "60",
         "362107",
         "981194.0",
         "Kobe Corbanie",
         "kobe corbanie",
         "Antwerp",
         null,
         "1.0",
         "0.0",
         "1.0",
         "False"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 1355
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_player_id</th>\n",
       "      <th>game_player_id</th>\n",
       "      <th>tf_player_name</th>\n",
       "      <th>game_player_name</th>\n",
       "      <th>tf_team_name</th>\n",
       "      <th>game_team_name</th>\n",
       "      <th>name_similarity</th>\n",
       "      <th>team_similarity</th>\n",
       "      <th>final_score</th>\n",
       "      <th>team_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34930</td>\n",
       "      <td>428920.0</td>\n",
       "      <td>Kevin Mac Allister</td>\n",
       "      <td>kevin mac allister</td>\n",
       "      <td>Union Saint-Gilloise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34930</td>\n",
       "      <td>428920.0</td>\n",
       "      <td>Kevin Mac Allister</td>\n",
       "      <td>kevin mac allister</td>\n",
       "      <td>Union Saint-Gilloise</td>\n",
       "      <td>royale union saint gilloise</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>1.15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52221</td>\n",
       "      <td>660746.0</td>\n",
       "      <td>Fedde Leysen</td>\n",
       "      <td>fedde leysen</td>\n",
       "      <td>PSV Eindhoven II</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52221</td>\n",
       "      <td>660746.0</td>\n",
       "      <td>Fedde Leysen</td>\n",
       "      <td>fedde leysen</td>\n",
       "      <td>Union Saint-Gilloise</td>\n",
       "      <td>royale union saint gilloise</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>1.15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3880</td>\n",
       "      <td>244221.0</td>\n",
       "      <td>Christian Burgess</td>\n",
       "      <td>christian burgess</td>\n",
       "      <td>Union Saint-Gilloise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>32977</td>\n",
       "      <td>535551.0</td>\n",
       "      <td>Bartosz Bialek</td>\n",
       "      <td>bartosz bialek</td>\n",
       "      <td>Vitesse</td>\n",
       "      <td>kas eupen</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>5514</td>\n",
       "      <td>90024.0</td>\n",
       "      <td>Alfred Finnbogason</td>\n",
       "      <td>alfred finnbogason</td>\n",
       "      <td>AS Eupen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>5514</td>\n",
       "      <td>90024.0</td>\n",
       "      <td>Alfred Finnbogason</td>\n",
       "      <td>alfred finnbogason</td>\n",
       "      <td>AS Eupen</td>\n",
       "      <td>sc heerenveen</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>5514</td>\n",
       "      <td>90024.0</td>\n",
       "      <td>Alfred Finnbogason</td>\n",
       "      <td>alfred finnbogason</td>\n",
       "      <td>AS Eupen</td>\n",
       "      <td>lyngby bk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>1.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>5514</td>\n",
       "      <td>90024.0</td>\n",
       "      <td>Alfred Finnbogason</td>\n",
       "      <td>alfred finnbogason</td>\n",
       "      <td>AS Eupen</td>\n",
       "      <td>kas eupen</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1355 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tf_player_id  game_player_id      tf_player_name    game_player_name  \\\n",
       "0            34930        428920.0  Kevin Mac Allister  kevin mac allister   \n",
       "1            34930        428920.0  Kevin Mac Allister  kevin mac allister   \n",
       "2            52221        660746.0        Fedde Leysen        fedde leysen   \n",
       "3            52221        660746.0        Fedde Leysen        fedde leysen   \n",
       "4             3880        244221.0   Christian Burgess   christian burgess   \n",
       "...            ...             ...                 ...                 ...   \n",
       "1807         32977        535551.0      Bartosz Bialek      bartosz bialek   \n",
       "1808          5514         90024.0  Alfred Finnbogason  alfred finnbogason   \n",
       "1809          5514         90024.0  Alfred Finnbogason  alfred finnbogason   \n",
       "1810          5514         90024.0  Alfred Finnbogason  alfred finnbogason   \n",
       "1811          5514         90024.0  Alfred Finnbogason  alfred finnbogason   \n",
       "\n",
       "              tf_team_name               game_team_name  name_similarity  \\\n",
       "0     Union Saint-Gilloise                          NaN              1.0   \n",
       "1     Union Saint-Gilloise  royale union saint gilloise              1.0   \n",
       "2         PSV Eindhoven II                          NaN              1.0   \n",
       "3     Union Saint-Gilloise  royale union saint gilloise              1.0   \n",
       "4     Union Saint-Gilloise                          NaN              1.0   \n",
       "...                    ...                          ...              ...   \n",
       "1807               Vitesse                    kas eupen              1.0   \n",
       "1808              AS Eupen                          NaN              1.0   \n",
       "1809              AS Eupen                sc heerenveen              1.0   \n",
       "1810              AS Eupen                    lyngby bk              1.0   \n",
       "1811              AS Eupen                    kas eupen              1.0   \n",
       "\n",
       "      team_similarity  final_score  team_match  \n",
       "0            0.000000         1.00       False  \n",
       "1            0.808511         1.15        True  \n",
       "2            0.000000         1.00       False  \n",
       "3            0.808511         1.15        True  \n",
       "4            0.000000         1.00       False  \n",
       "...               ...          ...         ...  \n",
       "1807         0.250000         1.00       False  \n",
       "1808         0.000000         1.00       False  \n",
       "1809         0.476190         1.00       False  \n",
       "1810         0.117647         1.00       False  \n",
       "1811         0.941176         1.15        True  \n",
       "\n",
       "[1355 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_players_solid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4927cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445\n"
     ]
    }
   ],
   "source": [
    "## map id from games to tf values table\n",
    "mapped_players_solid2 = (\n",
    "    mapped_players_solid\n",
    "    .drop_duplicates(subset=['game_player_id'],keep='first')\n",
    "    [['tf_player_id','game_player_id','game_player_name']]\n",
    "    .rename(columns={'tf_player_id':'sb_id'})\n",
    "    )\n",
    "\n",
    "print(len(mapped_players_solid2))\n",
    "tfValues2 = (\n",
    "    tfValues\n",
    "    .merge(mapped_players_solid2,left_on='player_id',right_on='game_player_id',how='left')\n",
    ")\n",
    "tfValues2 = tfValues2.dropna(subset='game_player_id')\n",
    "tfValues2 = tfValues2.drop(columns=['game_player_id','game_player_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f49677a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_season_and_avg_age(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    date_col: str,                 # e.g. 'marketvalue.Determined'\n",
    "    player_col: str,               # e.g. 'player_id' or 'player_name'\n",
    "    age_col: str = \"age\",          # existing rounded age column\n",
    "    season_col: str = \"season\",\n",
    "    avg_age_col: str = \"avg_age_season\",\n",
    "    date_format: str | None = \"%Y-%m-%d\",  # None = auto-infer\n",
    "    round_age: int | None = 2              # decimals for the average; None = no rounding\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a 'season' column based on `date_col` (Jul 1 -> Jun 30 => 'YYYY/YYYY+1'),\n",
    "    and an average age per (player, season) computed from the existing `age_col`.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Parse record dates robustly ----\n",
    "    raw = df[date_col].astype(str).str.strip()\n",
    "    raw = raw.replace({\"\": np.nan, \"nan\": np.nan, \"NaN\": np.nan, \"None\": np.nan})\n",
    "    if date_format is not None:\n",
    "        dates = pd.to_datetime(raw, format=date_format, errors=\"coerce\")\n",
    "    else:\n",
    "        dates = pd.to_datetime(raw, errors=\"coerce\", infer_datetime_format=True)\n",
    "    if dates.isna().mean() > 0.25:\n",
    "        fallback = pd.to_datetime(raw, errors=\"coerce\", infer_datetime_format=True)\n",
    "        if fallback.notna().sum() > dates.notna().sum():\n",
    "            dates = fallback\n",
    "\n",
    "    # ---- Season: YYYY/YYYY+1 ----\n",
    "    year = dates.dt.year\n",
    "    month = dates.dt.month\n",
    "    start_year = year.where(month >= 7, year - 1)\n",
    "    end_year = start_year + 1\n",
    "    season = (start_year.astype(\"Int64\").astype(str) + \"/\" + end_year.astype(\"Int64\").astype(str))\n",
    "    season = season.where(dates.notna(), pd.NA)\n",
    "    df[season_col] = season\n",
    "\n",
    "    # ---- Average age per player-season (from existing age column) ----\n",
    "    # Coerce age to numeric; ignore non-numeric as NaN\n",
    "    age_numeric = pd.to_numeric(df[age_col], errors=\"coerce\")\n",
    "    # Compute per (player, season) mean and broadcast back with transform\n",
    "    avg_age = df.assign(_age=age_numeric).groupby([player_col, season_col], dropna=False)[\"_age\"].transform(\"mean\")\n",
    "    if round_age is not None:\n",
    "        avg_age = avg_age.round(round_age)\n",
    "    df[avg_age_col] = avg_age\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_season(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    date_col: str,                 # e.g. 'marketvalue.Determined'\n",
    "    season_col: str = \"season\",\n",
    "    date_format: str | None = \"%Y-%m-%d\",  # None = auto-infer\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a 'season' column based on `date_col` (Jul 1 -> Jun 30 => 'YYYY/YYYY+1').\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Parse record dates robustly ----\n",
    "    raw = df[date_col].astype(str).str.strip()\n",
    "    raw = raw.replace({\"\": np.nan, \"nan\": np.nan, \"NaN\": np.nan, \"None\": np.nan})\n",
    "    if date_format is not None:\n",
    "        dates = pd.to_datetime(raw, format=date_format, errors=\"coerce\")\n",
    "    else:\n",
    "        dates = pd.to_datetime(raw, errors=\"coerce\", infer_datetime_format=True)\n",
    "\n",
    "    if dates.isna().mean() > 0.25:\n",
    "        # fallback attempt with flexible parsing\n",
    "        fallback = pd.to_datetime(raw, errors=\"coerce\", infer_datetime_format=True)\n",
    "        if fallback.notna().sum() > dates.notna().sum():\n",
    "            dates = fallback\n",
    "\n",
    "    # ---- Season: YYYY/YYYY+1 ----\n",
    "    year = dates.dt.year\n",
    "    month = dates.dt.month\n",
    "    start_year = year.where(month >= 7, year - 1)\n",
    "    end_year = start_year + 1\n",
    "    season = (start_year.astype(\"Int64\").astype(str) + \"/\" +\n",
    "              end_year.astype(\"Int64\").astype(str))\n",
    "    season = season.where(dates.notna(), pd.NA)\n",
    "\n",
    "    df[season_col] = season\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8933eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfValues3 = add_season_and_avg_age(tfValues2,date_col='marketValue.determined',player_col='player_id',age_col='age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2d2e9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sb_id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "season",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "marketValue.determined",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "age",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "f9699986-4667-4f8c-8c03-79251d646b65",
       "rows": [
        [
         "3205",
         "134805.0",
         "2019/2020",
         "0.325",
         "2020-04-08",
         "19"
        ],
        [
         "3207",
         "134805.0",
         "2020/2021",
         "1.5",
         "2021-02-17",
         "20"
        ],
        [
         "3212",
         "134805.0",
         "2021/2022",
         "2.0",
         "2022-04-12",
         "21"
        ],
        [
         "3216",
         "134805.0",
         "2022/2023",
         "3.3",
         "2023-06-09",
         "22"
        ],
        [
         "3220",
         "134805.0",
         "2023/2024",
         "2.5",
         "2024-06-04",
         "23"
        ],
        [
         "3224",
         "134805.0",
         "2024/2025",
         "2.2",
         "2025-06-12",
         "24"
        ],
        [
         "8009",
         "8071.0",
         "2016/2017",
         "0.3",
         "2017-06-15",
         "19"
        ],
        [
         "8010",
         "8071.0",
         "2017/2018",
         "0.3",
         "2018-05-16",
         "19"
        ],
        [
         "8012",
         "8071.0",
         "2018/2019",
         "0.8",
         "2019-06-27",
         "21"
        ],
        [
         "8021",
         "8071.0",
         "2019/2020",
         "1.6",
         "2020-04-08",
         "21"
        ],
        [
         "8027",
         "8071.0",
         "2020/2021",
         "1.2",
         "2021-06-07",
         "23"
        ],
        [
         "8033",
         "8071.0",
         "2021/2022",
         "0.85",
         "2022-04-12",
         "23"
        ],
        [
         "8039",
         "8071.0",
         "2022/2023",
         "0.65",
         "2023-06-09",
         "25"
        ],
        [
         "8043",
         "8071.0",
         "2023/2024",
         "0.7",
         "2024-06-04",
         "26"
        ],
        [
         "8047",
         "8071.0",
         "2024/2025",
         "0.7",
         "2025-06-12",
         "27"
        ],
        [
         "31548",
         "23892.0",
         "2017/2018",
         "0.25",
         "2018-06-03",
         "19"
        ],
        [
         "31562",
         "23892.0",
         "2018/2019",
         "0.75",
         "2019-06-10",
         "20"
        ],
        [
         "31564",
         "23892.0",
         "2019/2020",
         "0.8",
         "2020-04-08",
         "21"
        ],
        [
         "31567",
         "23892.0",
         "2020/2021",
         "1.2",
         "2021-06-07",
         "22"
        ],
        [
         "31582",
         "23892.0",
         "2021/2022",
         "0.7",
         "2022-04-12",
         "23"
        ],
        [
         "31592",
         "23892.0",
         "2022/2023",
         "0.7",
         "2023-06-09",
         "24"
        ],
        [
         "31607",
         "23892.0",
         "2023/2024",
         "5.0",
         "2024-06-04",
         "25"
        ],
        [
         "31609",
         "23892.0",
         "2024/2025",
         "4.5",
         "2025-05-23",
         "26"
        ],
        [
         "19872",
         "27647.0",
         "2019/2020",
         "1.3",
         "2020-04-08",
         "18"
        ],
        [
         "19884",
         "27647.0",
         "2020/2021",
         "1.0",
         "2021-06-04",
         "20"
        ],
        [
         "19892",
         "27647.0",
         "2021/2022",
         "1.0",
         "2022-06-20",
         "21"
        ],
        [
         "19902",
         "27647.0",
         "2022/2023",
         "1.5",
         "2023-06-09",
         "22"
        ],
        [
         "19912",
         "27647.0",
         "2023/2024",
         "2.0",
         "2024-06-04",
         "23"
        ],
        [
         "19922",
         "27647.0",
         "2024/2025",
         "1.8",
         "2025-06-12",
         "24"
        ],
        [
         "33317",
         "139016.0",
         "2017/2018",
         "0.1",
         "2018-06-07",
         "19"
        ],
        [
         "33321",
         "139016.0",
         "2018/2019",
         "0.85",
         "2019-05-28",
         "20"
        ],
        [
         "33323",
         "139016.0",
         "2019/2020",
         "0.8",
         "2020-04-08",
         "20"
        ],
        [
         "33325",
         "139016.0",
         "2020/2021",
         "0.8",
         "2021-04-11",
         "21"
        ],
        [
         "33327",
         "139016.0",
         "2021/2022",
         "1.2",
         "2021-12-01",
         "22"
        ],
        [
         "33331",
         "139016.0",
         "2022/2023",
         "2.0",
         "2023-06-27",
         "24"
        ],
        [
         "33337",
         "139016.0",
         "2023/2024",
         "2.0",
         "2024-06-04",
         "25"
        ],
        [
         "33339",
         "139016.0",
         "2024/2025",
         "1.5",
         "2025-06-13",
         "26"
        ],
        [
         "492",
         "132439.0",
         "2018/2019",
         "0.7",
         "2019-06-09",
         "19"
        ],
        [
         "494",
         "132439.0",
         "2019/2020",
         "1.3",
         "2020-04-08",
         "20"
        ],
        [
         "496",
         "132439.0",
         "2020/2021",
         "3.3",
         "2021-02-17",
         "21"
        ],
        [
         "506",
         "132439.0",
         "2021/2022",
         "4.0",
         "2022-04-12",
         "22"
        ],
        [
         "521",
         "132439.0",
         "2022/2023",
         "6.0",
         "2023-06-09",
         "23"
        ],
        [
         "531",
         "132439.0",
         "2023/2024",
         "5.0",
         "2024-06-04",
         "24"
        ],
        [
         "541",
         "132439.0",
         "2024/2025",
         "6.0",
         "2025-06-12",
         "25"
        ],
        [
         "23132",
         "406213.0",
         "2020/2021",
         "0.15",
         "2021-05-26",
         "20"
        ],
        [
         "23139",
         "406213.0",
         "2023/2024",
         "0.9",
         "2024-06-04",
         "23"
        ],
        [
         "23154",
         "406213.0",
         "2024/2025",
         "4.5",
         "2025-06-12",
         "24"
        ],
        [
         "33867",
         "16330.0",
         "2011/2012",
         "0.6",
         "2012-06-01",
         "21"
        ],
        [
         "33869",
         "16330.0",
         "2012/2013",
         "0.6",
         "2013-05-29",
         "22"
        ],
        [
         "33870",
         "16330.0",
         "2013/2014",
         "1.0",
         "2014-01-14",
         "22"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3231
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sb_id</th>\n",
       "      <th>season</th>\n",
       "      <th>value</th>\n",
       "      <th>marketValue.determined</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>134805.0</td>\n",
       "      <td>2019/2020</td>\n",
       "      <td>0.325</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3207</th>\n",
       "      <td>134805.0</td>\n",
       "      <td>2020/2021</td>\n",
       "      <td>1.500</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>134805.0</td>\n",
       "      <td>2021/2022</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>134805.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>3.300</td>\n",
       "      <td>2023-06-09</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>134805.0</td>\n",
       "      <td>2023/2024</td>\n",
       "      <td>2.500</td>\n",
       "      <td>2024-06-04</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22154</th>\n",
       "      <td>16341.0</td>\n",
       "      <td>2020/2021</td>\n",
       "      <td>12.000</td>\n",
       "      <td>2021-06-07</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22156</th>\n",
       "      <td>16341.0</td>\n",
       "      <td>2021/2022</td>\n",
       "      <td>8.000</td>\n",
       "      <td>2022-06-07</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22166</th>\n",
       "      <td>16341.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>4.500</td>\n",
       "      <td>2023-06-23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22176</th>\n",
       "      <td>16341.0</td>\n",
       "      <td>2023/2024</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2024-06-04</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22196</th>\n",
       "      <td>16341.0</td>\n",
       "      <td>2024/2025</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2025-06-12</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3231 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sb_id     season   value marketValue.determined age\n",
       "3205   134805.0  2019/2020   0.325             2020-04-08  19\n",
       "3207   134805.0  2020/2021   1.500             2021-02-17  20\n",
       "3212   134805.0  2021/2022   2.000             2022-04-12  21\n",
       "3216   134805.0  2022/2023   3.300             2023-06-09  22\n",
       "3220   134805.0  2023/2024   2.500             2024-06-04  23\n",
       "...         ...        ...     ...                    ...  ..\n",
       "22154   16341.0  2020/2021  12.000             2021-06-07  21\n",
       "22156   16341.0  2021/2022   8.000             2022-06-07  22\n",
       "22166   16341.0  2022/2023   4.500             2023-06-23  23\n",
       "22176   16341.0  2023/2024   5.000             2024-06-04  24\n",
       "22196   16341.0  2024/2025   1.000             2025-06-12  25\n",
       "\n",
       "[3231 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfValues3 = (\n",
    "    tfValues3[['player_name','sb_id','season','value','marketValue.determined','age']]\n",
    "    .sort_values(by=['player_name','sb_id','marketValue.determined'],ascending=True)\n",
    "\n",
    ")\n",
    "\n",
    "tfValues4 = tfValues3.drop_duplicates(subset=['player_name','season'],keep='last')\n",
    "tfValues4 = tfValues4.drop(columns=['player_name'])\n",
    "tfValues4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8885320f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6958\n",
      "966\n"
     ]
    }
   ],
   "source": [
    "seasonStats_merged = seasonStats.merge(tfValues4,left_on=['player_id','season_name'],right_on=['sb_id','season'],how='left')\n",
    "print(len(seasonStats_merged))\n",
    "\n",
    "seasonStats_merged2 = seasonStats_merged.dropna(subset=['value'])\n",
    "print(len(seasonStats_merged2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "495d0a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/2101697413.py:71: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  fallback = pd.to_datetime(raw, errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "## add club elo as a factor for that period:\n",
    "dfELO = pd.read_csv('datasets/Elo_teams_mapped.csv',sep=',')\n",
    "dfELO2 = add_season(dfELO,date_col='Date_ref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfd1e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfElo3 = dfELO2[['Match1','season','Elo']].groupby(['Match1','season']).mean().reset_index().rename(columns={'Match1':'team_name'})\n",
    "\n",
    "seasonStats_merged3 = seasonStats_merged2.merge(dfElo3,on=['team_name','season'],how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8391b966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
      "/var/folders/gr/grh3033930d1vhxcd4gdjy6m0000gn/T/ipykernel_16621/3333517254.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_sorted[\"is_baseline\"] = data_sorted.groupby(\"player_id\")[\"season\"].rank(method=\"first\").eq(1).astype(int)\n"
     ]
    }
   ],
   "source": [
    "def calculate_player_improvement_with_flag(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate percent change for all 'player_match_' columns compared to the previous period for each player.\n",
    "    Adds a column 'is_baseline' = 1 if it's the first period for a player, else 0.\n",
    "    \"\"\"\n",
    "    # Find all columns that start with 'player_match_'\n",
    "    season_cols = [col for col in data.columns if col.startswith(\"player_season_\")]\n",
    "    season_cols = [col for col in season_cols if 'minutes' not in col]\n",
    "    \n",
    "    # Sort by player and period\n",
    "    data_sorted = data.sort_values(by=[\"player_id\", \"season\"]).copy()\n",
    "    \n",
    "    # Group by player and calculate percent change vs. previous period\n",
    "    for col in season_cols:\n",
    "        data_sorted[f\"{col}_improvement\"] = data_sorted.groupby(\"player_id\")[col].pct_change() * 100\n",
    "    \n",
    "    # Mark baseline periods (first for each player)\n",
    "    data_sorted[\"is_baseline\"] = data_sorted.groupby(\"player_id\")[\"season\"].rank(method=\"first\").eq(1).astype(int)\n",
    "    \n",
    "    return data_sorted\n",
    "\n",
    "## Apply improvement function\n",
    "seasonStats_merged4 = calculate_player_improvement_with_flag(seasonStats_merged3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7edd5d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benfica', 'RSC Anderlecht', 'Standard Liège', 'Antwerp',\n",
       "       'Almere City', 'Beerschot', 'Sporting Charleroi', 'Gent',\n",
       "       'Union Saint-Gilloise', 'Sint-Truiden', 'Mechelen', 'AS Eupen',\n",
       "       'BSC Young Boys', 'OH Leuven', 'Westerlo', 'Club Brugge',\n",
       "       'KRC Genk', 'Kortrijk', 'RWDM', 'Servette', 'AZ Alkmaar', 'Ajax',\n",
       "       'Cercle Brugge', 'Zulte Waregem', 'Feyenoord', 'KV Oostende',\n",
       "       'FC Lausanne Sport', 'Beveren', 'Sturm Graz', 'Go Ahead Eagles',\n",
       "       'FC Groningen', 'Fortuna Sittard', 'Dender', 'PEC Zwolle',\n",
       "       'Willem II', 'RKC Waalwijk', 'RFC Seraing', 'Rio Ave',\n",
       "       'Heracles Almelo', 'FC Utrecht', 'Twente', 'FC Emmen',\n",
       "       'FC Volendam', 'Vitesse', 'Sparta Rotterdam', 'SC Heerenveen',\n",
       "       'Santa Clara', 'Grasshopper', 'Luzern', 'Royal Excel Mouscron',\n",
       "       'NAC Breda', 'WSG Tirol', 'Basel', 'Austria Wien', 'NEC',\n",
       "       'Sporting CP', 'FC Arouca', 'LASK', 'Lugano',\n",
       "       'FC Stade Lausanne-Ouchy', 'Rapid Wien', 'Sion'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasonStats_merged4['team_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "abc1be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonStats_merged4.to_csv('model_data/merged_season_data.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393362b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
